---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: "3"

vars:
  TALOS_DIR: "{{.ROOT_DIR}}/talos"
  # renovate: datasource=docker depName=ghcr.io/siderolabs/installer
  TALOS_VERSION: v1.11.5
  TALOS_SCHEMATIC_ID: 76c84cdf5aa9d680bbb6bdd1f5d643d11462b5ce7f2b273c1f8d22e8f5e0af2b
  # renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet
  KUBERNETES_VERSION: v1.34.1
  TALOS_SCRIPTS_DIR: "{{.ROOT_DIR}}/.taskfiles/Talos/scripts"

tasks:
  generate:
    desc: Generate Talos configuration
    dir: "{{.TALOS_DIR}}"
    cmd: op run --env-file=".env" -- talhelper genconfig --debug -c talconfig.yaml -e talenv.yaml -s talsecret.yaml
    preconditions:
      - test -f {{.ROOT_DIR}}/talos/talconfig.yaml
      - test -f {{.ROOT_DIR}}/talos/talenv.yaml
      - test -f {{.ROOT_DIR}}/talos/talsecret.yaml

  apply:
    desc: Apply Talos configuration
    dir: "{{.TALOS_DIR}}"
    cmd: op run --env-file=".env" -- talhelper gencommand apply --extra-flags=--insecure | bash

  bootstrap:
    desc: Bootstrap Talos nodes
    dir: "{{.TALOS_DIR}}"
    cmd: op run --env-file=".env" -- talhelper gencommand bootstrap --extra-flags=--insecure | bash

  upgrade:
    desc: Upgrade Talos on a node
    cmd: bash {{.TALOS_SCRIPTS_DIR}}/upgrade.sh "{{.node}}" "{{.TALOS_SCHEMATIC_ID}}:{{.TALOS_VERSION}}" "{{.rollout}}"
    vars:
      rollout: '{{.rollout | default "false"}}'
    requires:
      vars: ["node"]
    preconditions:
      - test -f {{.TALOS_DIR}} || test -f $HOME/.talos/config
      - talosctl config info >/dev/null 2>&1
      - talosctl --nodes {{.node}} get machineconfig >/dev/null 2>&1

  upgrade-rollout:
    desc: Rollout Talos upgrade on all nodes
    cmds:
      - kubectl get ns -o jsonpath='{.items[*].metadata.name}' | xargs -n1 -I {} flux suspend kustomization --all -n {}
      - kubectl cnpg maintenance set --reusePVC --all-namespaces
      - for: { var: nodes, split: "," }
        task: upgrade
        vars:
          node: "{{.ITEM}}"
          rollout: "true"
      - kubectl cnpg maintenance unset --reusePVC --all-namespaces
      - kubectl get ns -o jsonpath='{.items[*].metadata.name}' | xargs -n1 -I {} flux resume kustomization --all -n {}
      - task: :kubernetes:delete-failed-pods
    vars:
      nodes:
        sh: talosctl config info --output json | jq --join-output '[.nodes[]] | join(",")'
    preconditions:
      - talosctl config info >/dev/null 2>&1
      - talosctl --nodes {{.nodes}} get machineconfig >/dev/null 2>&1

  upgrade-k8s:
    desc: Upgrade k8s on a node
    cmd: talosctl --nodes {{.node}} upgrade-k8s --to {{.to}}
    requires:
      vars: ["node", "to"]
    preconditions:
      - { msg: "Node not found", sh: "talosctl --nodes {{.node}} get machineconfig" }

  reboot-node:
    desc: Reboot Talos on a single node [IP=required] [MODE=powercycle]
    cmd: talosctl --nodes {{.IP}} reboot --mode={{.MODE}}
    vars:
      MODE: '{{.MODE | default "powercycle"}}'
    requires:
      vars: [IP]
    preconditions:
      - talosctl --nodes {{.IP}} get machineconfig
      - which talosctl

  fetch-kubeconfig:
    desc: Generate talos kubeconfig
    dir: "{{.TALOS_DIR}}"
    cmd: until talhelper gencommand kubeconfig --extra-flags "--force" | bash; do sleep 10; done

  nuke:
    desc: Resets nodes back to maintenance mode so you can re-deploy again straight after
    prompt: This will DESTROY your cluster and reset the nodes back to maintenance mode... continue?
    dir: "{{.TALOS_DIR}}"
    cmd: talhelper gencommand reset --extra-flags "--reboot --system-labels-to-wipe STATE --system-labels-to-wipe EPHEMERAL --graceful=false --wait=false" | bash
